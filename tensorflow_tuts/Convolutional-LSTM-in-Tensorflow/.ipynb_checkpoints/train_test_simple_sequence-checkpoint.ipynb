{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random \n",
    "\n",
    "import layer_def as ld\n",
    "import BasicConvLSTMCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dim = (32,32) \n",
    "image_num = 3200\n",
    "batch_size_ = 16\n",
    "seq_len_ = 4\n",
    "seq_start_ = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
    "\n",
    "\n",
    "tf.app.flags.DEFINE_string('train_dir', './checkpoints/train_store_conv_lstm',\n",
    "                            \"\"\"dir to store trained net\"\"\")\n",
    "tf.app.flags.DEFINE_integer('seq_length', 10,\n",
    "                            \"\"\"size of hidden layer\"\"\")\n",
    "tf.app.flags.DEFINE_integer('seq_start', 5,\n",
    "                            \"\"\" start of seq generation\"\"\")\n",
    "tf.app.flags.DEFINE_integer('max_step', 200000,\n",
    "                            \"\"\"max num of steps\"\"\")\n",
    "tf.app.flags.DEFINE_float('keep_prob', .8,\n",
    "                            \"\"\"for dropout\"\"\")\n",
    "tf.app.flags.DEFINE_float('lr', .001,\n",
    "                            \"\"\"for dropout\"\"\")\n",
    "tf.app.flags.DEFINE_integer('batch_size', 16,\n",
    "                            \"\"\"batch size for training\"\"\")\n",
    "tf.app.flags.DEFINE_float('weight_init', .1,\n",
    "                            \"\"\"weight init for fully connected layers\"\"\")\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_seq_len(data, seq_len = seq_len_):\n",
    "    reshaped_x = []\n",
    "    for x in data:\n",
    "        temp = x.reshape([-1,seq_len,x.shape[1],x.shape[2]])\n",
    "        reshaped_x.append(temp)\n",
    "    return reshaped_x\n",
    "\n",
    "\n",
    "def gen_batch(data, batch_size = batch_size_):\n",
    "    i = 0\n",
    "    X = data[0]\n",
    "    Y = data[1]\n",
    "    for i in range(i ,batch_size, len(X)):\n",
    "        yield X[i: batch_size], Y[i:batch_size]\n",
    "        \n",
    "        \n",
    "def my_shuffle(data):\n",
    "    \n",
    "    suffled_x = []\n",
    "    start_state = random.getstate()\n",
    "    for x in data:\n",
    "        random.shuffle(x)\n",
    "        random.setstate(start_state)\n",
    "        suffled_x.append(x)        \n",
    "    return suffled_x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_X = np.asarray([np.random.random(img_dim)*n/1000 for n in range(image_num)])\n",
    "raw_Y = np.cumsum(raw_X,axis=0)\n",
    "\n",
    "data = (raw_X, raw_Y)\n",
    "reshaped_data = reshape_seq_len(data, seq_len_)\n",
    "shuffled_data = my_shuffle(reshaped_data)\n",
    "data_generator = gen_batch(shuffled_data, batch_size_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(inputs, hidden, lstm=True):\n",
    "    conv1 = ld.conv_layer(inputs, 3, 2, 8, \"encode_1\")\n",
    "    # conv2\n",
    "    conv2 = ld.conv_layer(conv1, 3, 1, 8, \"encode_2\")\n",
    "    # conv3\n",
    "    conv3 = ld.conv_layer(conv2, 3, 2, 8, \"encode_3\")\n",
    "    # conv4\n",
    "    conv4 = ld.conv_layer(conv3, 1, 1, 4, \"encode_4\")\n",
    "    y_0 = conv4\n",
    "    if lstm:\n",
    "    # conv lstm cell \n",
    "        with tf.variable_scope('conv_lstm', initializer = tf.random_uniform_initializer(-.01, 0.1), reuse=tf.AUTO_REUSE):\n",
    "                cell = BasicConvLSTMCell.BasicConvLSTMCell([8,8], [3,3], 4)\n",
    "                if hidden is None:\n",
    "                    hidden = cell.zero_state(FLAGS.batch_size, tf.float32) \n",
    "                y_1, hidden = cell(y_0, hidden)\n",
    "    else:\n",
    "        y_1 = ld.conv_layer(y_0, 3, 1, 8, \"encode_3\")\n",
    "\n",
    "    # conv5\n",
    "    conv5 = ld.transpose_conv_layer(y_1, 1, 1, 8, \"decode_5\")\n",
    "    # conv6\n",
    "    conv6 = ld.transpose_conv_layer(conv5, 3, 2, 8, \"decode_6\")\n",
    "    # conv7\n",
    "    conv7 = ld.transpose_conv_layer(conv6, 3, 1, 8, \"decode_7\")\n",
    "    # x_1 \n",
    "    x_1 = ld.transpose_conv_layer(conv7, 3, 2, 3, \"decode_8\", True) # set activation to linear\n",
    "\n",
    "    return x_1, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "     with tf.Graph().as_default():\n",
    "        # make inputs\n",
    "        x = tf.placeholder(tf.float32, [None, seq_len_, 32, 32, 1])\n",
    "\n",
    "        # possible dropout inside\n",
    "        keep_prob = tf.placeholder(\"float\")\n",
    "        x_dropout = tf.nn.dropout(x, keep_prob)\n",
    "\n",
    "        # create network\n",
    "        x_unwrap = []\n",
    "\n",
    "        # conv network\n",
    "        hidden = None\n",
    "        for i in range(seq_len_):\n",
    "            print(i)\n",
    "            x_1, hidden = network(x_1, hidden)\n",
    "        x_unwrap.append(x_1)\n",
    "\n",
    "        # pack them all together \n",
    "        x_unwrap = tf.stack(x_unwrap)\n",
    "        x_unwrap = tf.transpose(x_unwrap, [1,0,2,3,4])\n",
    "\n",
    "        # this part will be used for generating video\n",
    "        x_unwrap_g = []\n",
    "        hidden_g = None\n",
    "        for i in range(50):\n",
    "            if i < seq_start_:\n",
    "                x_1_g, hidden_g = network(x_dropout[:,i,:,:,:], hidden_g)\n",
    "            else:\n",
    "                x_1_g, hidden_g = network(x_1_g, hidden_g)\n",
    "            x_unwrap_g.append(x_1_g)\n",
    "\n",
    "        # pack them generated ones\n",
    "        x_unwrap_g = tf.stack(x_unwrap_g)\n",
    "        x_unwrap_g = tf.transpose(x_unwrap_g, [1,0,2,3,4])\n",
    "\n",
    "        # calc total loss (compare x_t to x_t+1)\n",
    "        loss = tf.nn.l2_loss(x[:,seq_start_+1:,:,:,:] - x_unwrap[:,seq_start_:,:,:,:])\n",
    "        tf.summary.scalar('loss', loss)\n",
    "\n",
    "        # training\n",
    "        train_op = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "\n",
    "        # List of all Variables\n",
    "        variables = tf.global_variables()\n",
    "\n",
    "        # Build a saver\n",
    "        saver = tf.train.Saver(tf.global_variables())   \n",
    "\n",
    "        # Summary op\n",
    "        summary_op = tf.summary.merge_all()\n",
    "\n",
    "        # Build an initialization operation to run below.\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        # Start running operations on the Graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Trying to share variable encode_1_conv/weights/weights, but specified shape (3, 3, 3, 8) and found shape (3, 3, 1, 8).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-4dbf3188dd46>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mx_1_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_dropout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0mx_1_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_1_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mx_unwrap_g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_1_g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-e50eb997243f>\u001b[0m in \u001b[0;36mnetwork\u001b[0;34m(inputs, hidden, lstm)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encode_1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m# conv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mconv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encode_2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# conv3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Learning_resources-/codes/python_tutorial/Convolutional-LSTM-in-Tensorflow/layer_def.py\u001b[0m in \u001b[0;36mconv_layer\u001b[0;34m(inputs, kernel_size, stride, num_features, idx, linear)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0minput_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_variable_with_weight_decay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weights'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstddev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0mbiases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_variable_on_cpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'biases'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Learning_resources-/codes/python_tutorial/Convolutional-LSTM-in-Tensorflow/layer_def.py\u001b[0m in \u001b[0;36m_variable_with_weight_decay\u001b[0;34m(name, shape, stddev, wd)\u001b[0m\n\u001b[1;32m     60\u001b[0m   \"\"\"\n\u001b[1;32m     61\u001b[0m   var = _variable_on_cpu(name, shape,\n\u001b[0;32m---> 62\u001b[0;31m                          tf.truncated_normal_initializer(stddev=stddev))\n\u001b[0m\u001b[1;32m     63\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mweight_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weight_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Learning_resources-/codes/python_tutorial/Convolutional-LSTM-in-Tensorflow/layer_def.py\u001b[0m in \u001b[0;36m_variable_on_cpu\u001b[0;34m(name, shape, initializer)\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/cpu:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTO_REUSE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1315\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m       constraint=constraint)\n\u001b[0m\u001b[1;32m   1318\u001b[0m get_variable_or_local_docstring = (\n\u001b[1;32m   1319\u001b[0m     \"\"\"%s\n",
      "\u001b[0;32m~/.virtualenvs/3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1077\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m           \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/.virtualenvs/3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m    423\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m           \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[0;32m~/.virtualenvs/3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    392\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m           use_resource=use_resource, constraint=constraint)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    736\u001b[0m         raise ValueError(\"Trying to share variable %s, but specified shape %s\"\n\u001b[1;32m    737\u001b[0m                          \" and found shape %s.\" % (name, shape,\n\u001b[0;32m--> 738\u001b[0;31m                                                    found_var.get_shape()))\n\u001b[0m\u001b[1;32m    739\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0mdtype_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Trying to share variable encode_1_conv/weights/weights, but specified shape (3, 3, 3, 8) and found shape (3, 3, 1, 8)."
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
